{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download poppler from here - https://github.com/oschwartz10612/poppler-windows/releases/\n",
    "\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "\n",
    "def pdf_to_img_converter(pdf_path: str, output_img_folder_path: str) -> None:\n",
    "\n",
    "    os.makedirs(output_img_folder_path, exist_ok=True)\n",
    "\n",
    "    images = convert_from_path(pdf_path, poppler_path=r\"C:/Program Files (x86)/poppler-23.07.0/Library/bin\")\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(os.path.join(output_img_folder_path, f\"image_{str(i)}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'D:/text-summarization-using-langchain/Machine_learning_notes.pdf'\n",
    "output_img_folder_path = 'D:/text-summarization-using-langchain/pdf_images/'\n",
    "\n",
    "pdf_to_img_converter(pdf_path=pdf_path, output_img_folder_path=output_img_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'\n",
    "\n",
    "\n",
    "def img_to_txt_converter(output_txt_folder_path: str, img_pdf_folder_path: str) -> None:\n",
    "\n",
    "    os.makedirs(output_txt_folder_path, exist_ok=True)\n",
    "\n",
    "    for i, resume in enumerate(os.listdir(img_pdf_folder_path)):\n",
    "        img = cv2.imread(img_pdf_folder_path + \"/\" + resume)\n",
    "        img = cv2.resize(img, (1000, 1100))\n",
    "        text = pytesseract.image_to_string(img)\n",
    "\n",
    "        fname = os.path.join(output_txt_folder_path, f\"txt_{str(i)}.txt\")\n",
    "        with open(fname, \"w\", encoding='utf-8') as file:\n",
    "            file.write(text)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pdf_folder_path = 'D:/text-summarization-using-langchain/pdf_images/'\n",
    "output_txt_folder_path = 'D:/text-summarization-using-langchain/pdf_text/'\n",
    "\n",
    "img_to_txt_converter(output_txt_folder_path=output_txt_folder_path, img_pdf_folder_path=img_pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_txt_files(txt_files_path: str, output_txt_file_path: str) -> None:\n",
    "\n",
    "    read_files = os.listdir(txt_files_path)\n",
    "    with open(output_txt_file_path, \"wb\") as outfile:\n",
    "        for f in read_files:\n",
    "            with open(txt_files_path + \"/\" + f, \"rb\") as infile:\n",
    "                outfile.write(infile.read())\n",
    "\n",
    "        outfile.close()\n",
    "\n",
    "\n",
    "concatenated_file_path = 'D:/text-summarization-using-langchain/output.txt'\n",
    "\n",
    "concatenate_txt_files(txt_files_path=output_txt_folder_path, output_txt_file_path=concatenated_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = 'D:/text-summarization-using-langchain/output.txt'\n",
    "\n",
    "with open(article, 'r') as file:\n",
    "    essay = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63126"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "llm.get_num_tokens(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=8000, chunk_overlap=1000)\n",
    "\n",
    "docs = text_splitter.create_documents([essay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 33 documents and the first one has 1988 tokens\n"
     ]
    }
   ],
   "source": [
    "num_docs = len(docs)\n",
    "\n",
    "num_tokens_first_doc = llm.get_num_tokens(docs[0].page_content)\n",
    "\n",
    "print (f\"Now we have {num_docs} documents and the first one has {num_tokens_first_doc} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce',\n",
    "#                                      verbose=True # Set verbose=True if you want to see the prompts being used\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This article covers topics related to Machine Learning and Data Mining, such as Linear and Nonlinear Regression, Quadraties, Basic Probability Theory, Probability Density Functions, Estimation, Hidden Markov Models, and Bayesian Methods. It provides an overview of the different types of Machine Learning, the Markov property, Bayesian approaches to model selection, and the importance of avoiding overfitting. It also discusses methods such as Monte Carlo, Principal Components Analysis (PCA), the Method of Lagrange Multipliers, K-means and K-medoids clustering, Support Vector Machines (SVMs), AdaBoost, the Expectation-Maximization algorithm, K-Nearest Neighbors regression, and probability theory.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = summary_chain.run(docs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "map_prompt = \"\"\"\n",
    "Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_prompt = \"\"\"\n",
    "Write a concise summary of the following text delimited by triple backquotes.\n",
    "Return your response in bullet points which covers the key points of the text.\n",
    "```{text}```\n",
    "BULLET POINT SUMMARY:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(llm=llm,\n",
    "                                     chain_type='map_reduce',\n",
    "                                     map_prompt=map_prompt_template,\n",
    "                                     combine_prompt=combine_prompt_template,\n",
    "#                                      verbose=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Machine Learning and Data Mining topics include Linear Regression, Nonlinear Regression, Quadraties, Basic Probability Theory, Probability Density Functions, Estimation, Hidden Markov Models, and Bayesian Methods.\\n- Monte Carlo methods are used to approximate expected values and sample from distributions.\\n- Principal Components Analysis (PCA) is an unsupervised learning algorithm used to reduce the dimensionality of high-dimensional data.\\n- Lagrange Multipliers method is used to optimize a function with multiple constraints.\\n- K-means and K-medoids clustering are two common approaches to clustering data.\\n- Mixtures of Gaussians is a generalization of K-means clustering that can handle oblong clusters and overlapping clusters.\\n- The Viterbi algorithm and the Forward-Backward algorithm are two dynamic programming approaches used to compute the most likely sequence of states given a data set and a known HMM model.\\n- Support Vector Machines (SVMs) are a type of optimization problem that can be used to classify data points.\\n- Class conditionals and logistic regression are two approaches to classification, with logistic regression being more efficient.\\n- Generative and discriminative models are two'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = summary_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Machine Learning and Data Mining topics include Linear Regression, Nonlinear Regression, Quadraties, Basic Probability Theory, Probability Density Functions, Estimation, Hidden Markov Models, and Bayesian Methods.\n",
      "- Monte Carlo methods are used to approximate expected values and sample from distributions.\n",
      "- Principal Components Analysis (PCA) is an unsupervised learning algorithm used to reduce the dimensionality of high-dimensional data.\n",
      "- Lagrange Multipliers method is used to optimize a function with multiple constraints.\n",
      "- K-means and K-medoids clustering are two common approaches to clustering data.\n",
      "- Mixtures of Gaussians is a generalization of K-means clustering that can handle oblong clusters and overlapping clusters.\n",
      "- The Viterbi algorithm and the Forward-Backward algorithm are two dynamic programming approaches used to compute the most likely sequence of states given a data set and a known HMM model.\n",
      "- Support Vector Machines (SVMs) are a type of optimization problem that can be used to classify data points.\n",
      "- Class conditionals and logistic regression are two approaches to classification, with logistic regression being more efficient.\n",
      "- Generative and discriminative models are two\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
